# NLP_project
# Projet d'Analyse de Sentiment Avanc√©e pour AeroPulse Corp. (NLP avec BERT)

## üéØ Contexte du Projet & Objectif M√©tier

Ce projet a √©t√© men√© pour **AeroPulse Corp.**, un acteur majeur dans l'a√©ronautique et les syst√®mes de d√©fense, qui fait face √† un volume colossal de donn√©es textuelles non structur√©es (rapports de maintenance, journaux de bord, retours clients, etc.). L'objectif √©tait de d√©velopper un syst√®me d'**analyse de sentiment avanc√©** pour :

-   **D√©tection Pr√©coce des Probl√®mes :** Identifier rapidement les signaux faibles d'incidents ou de d√©faillances dans les rapports textuels pour une maintenance pr√©dictive et proactive.
-   **Am√©lioration du Support Client :** Classer et prioriser les retours clients, optimiser la gestion des demandes et identifier les tendances d'insatisfaction.
-   **Compr√©hension de la Voix du Client :** Extraire des insights pr√©cieux sur la perception des produits et services √† partir de flux textuels.

## üöÄ Approche Technique : Mod√®le de Transformeur Pr√©-entra√Æn√© (BERT)

Nous avons mis en ≈ìuvre une solution de pointe en Traitement du Langage Naturel (NLP) bas√©e sur les **Transformeurs Pr√©-entra√Æn√©s**, qui sont √† la base des mod√®les de langage les plus performants actuels.

### **1. Acquisition & Pr√©paration des Donn√©es Textuelles**

*   **Source :** Dataset "Twitter US Airline Sentiment" de Kaggle (`tweets.csv`), simulant des retours clients courts et informels.
*   **Nettoyage Robuste (avec SpaCy) :**
    *   Conversion en minuscules, suppression des URLs, mentions (@), hashtags (#), ponctuation et chiffres.
    *   **Tokenisation & Lemmatisation :** R√©duction des mots √† leur forme de base (`running` -> `run`) et suppression des mots vides de sens (`stop words`) pour normaliser le texte et r√©duire le bruit.
    *   Gestion des valeurs manquantes et des doublons.
*   **Variable Cible :** Simplification en classification binaire (`binary_sentiment` : `1` pour `n√©gatif`, `0` pour `non-n√©gatif` (positif/neutre)), priorisant la d√©tection des probl√®mes.

### **2. Vectorisation du Texte avec le Tokenizer de BERT**

Contrairement aux m√©thodes traditionnelles comme TF-IDF, les Transformeurs utilisent leur propre m√©canisme de repr√©sentation du langage :
*   **Tokenizer de BERT :** Le texte nettoy√© est converti en s√©quences d'identifiants num√©riques (`input_ids`) et de masques d'attention (`attention_mask`), pr√©par√©s sp√©cifiquement pour l'architecture de BERT. Ce processus g√®re √©galement le padding et la troncation des s√©quences.

### **3. Mod√©lisation : Fine-tuning d'un Mod√®le BERT**

*   **Architecture :** Utilisation de `BertForSequenceClassification` (bas√© sur `bert-base-uncased`), un mod√®le de Transformeur pr√©-entra√Æn√© de Hugging Face.
*   **Apprentissage par Transfert :** Le mod√®le, d√©j√† entra√Æn√© sur des quantit√©s massives de texte pour comprendre la langue, a √©t√© **ajust√© finement (fine-tuned)** sur notre dataset de tweets pour la t√¢che sp√©cifique d'analyse de sentiment.
*   **Optimisation :** Entra√Ænement sur GPU (Google Colab), utilisant `AdamW` comme optimiseur et un faible taux d'apprentissage.

### **4. √âvaluation des Performances : Des R√©sultats de Pointe**
Le mod√®le a √©t√© √©valu√© sur un ensemble de validation d√©di√© (20% des donn√©es), simulant des donn√©es non vues.

*   **Classe d'int√©r√™t (Sentiment N√©gatif) :**
    *   **Pr√©cision : 84%** (84% des tweets pr√©dits "n√©gatifs" sont r√©ellement n√©gatifs - faible fausse alarme).
    *   **Rappel : 89%** (89% des tweets r√©ellement "n√©gatifs" ont √©t√© d√©tect√©s - peu de probl√®mes manqu√©s).
    *   **F1-Score : 87%** (Excellent √©quilibre entre pr√©cision et rappel).
*   **Capacit√© de Discrimination :**
    *   **AUC-ROC : 0.90** (Excellente capacit√© √† distinguer les sentiments n√©gatifs des autres).
    *   **PR-AUC : 0.93** (Performance exceptionnelle pour la d√©tection de la classe d'int√©r√™t dans un contexte de d√©s√©quilibre).

Ces m√©triques placent notre mod√®le parmi les solutions de pointe, capable de d√©tecter les probl√®mes avec une grande fiabilit√©.

### **5. IA Explicable (XAI) : Comprendre les D√©cisions du Mod√®le**

Pour d√©mystifier la "bo√Æte noire" de BERT, nous avons explor√© l'IA explicable (XAI) :
*   **Objectif :** Comprendre quels mots influencent le plus la pr√©diction du sentiment.
*   **M√©thode :** Utilisation des **SHAP values** (KernelExplainer pour une vue globale et Force Plot pour une explication individuelle). Bien que gourmande en ressources, cette approche fournit des insights pr√©cieux.
*   **Insights Cl√©s :** Nous avons pu identifier des mots sp√©cifiques (`delayed`, `cancelled`, `lost`, `worst`) qui poussent fortement la pr√©diction vers le n√©gatif, et d'autres (`thanks`, `great`) vers le non-n√©gatif. Ces informations sont cruciales pour AeroPulse Corp. pour comprendre la nature des probl√®mes signal√©s.

## üöÄ **D√©ploiement & Impact Op√©rationnel**

Le mod√®le entra√Æn√© et son tokenizer ont √©t√© sauvegard√©s, pr√™ts pour le d√©ploiement.

*   **API Flask (D√©monstrateur) :** Une API web simple a √©t√© cr√©√©e (`app.py`), permettant d'envoyer un texte (tweet) et de recevoir une pr√©diction de sentiment en temps r√©el. Cette API peut √™tre int√©gr√©e aux syst√®mes existants d'AeroPulse Corp.
*   **B√©n√©fices Concrets pour AeroPulse Corp. :**
    *   **Alertes Automatis√©es :** D√©tecter et prioriser les rapports critiques.
    *   **Analyse de Tendances :** Comprendre les √©volutions du sentiment client sur leurs produits/services.
    *   **Optimisation des Ressources :** Acheminer les demandes de support vers les bonnes √©quipes plus rapidement.
    *   **Am√©lioration Produit/Service :** Utiliser les retours n√©gatifs cibl√©s pour l'am√©lioration continue.

## üõ†Ô∏è **Technologies Utilis√©es**

*   **Langage :** Python
*   **Librairies :** Pandas, NumPy, Matplotlib, Seaborn, SpaCy, Hugging Face Transformers, PyTorch, scikit-learn, Flask, SHAP.

---
